{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to modify `KNNClassifier` class from your practice in class. The `KNNClassifier` class with empty methods is provided below. Please, modify it to do all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "class KNNClassifier(object):\n",
    "    \n",
    "    def __init__(self, max_dist=1., use_kd_tree=False, use_weights=False):\n",
    "        \"\"\"\n",
    "        This is a constructor of the class. \n",
    "        Here you can define parameters (max_dist) of the class and \n",
    "        attributes, that are visible within all methods of the class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_dist : float\n",
    "            Maximum distance between an object and its neighbors.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make this parameter visible in all methods of the class\n",
    "        self.max_dist = max_dist\n",
    "        self.use_kd_tree = use_kd_tree\n",
    "        self.use_weights = use_weights\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method trains the KNN classifier. \n",
    "        Actualy, the KNN classifier has no training procedure.\n",
    "        It just remembers data (X, y) that will be used for predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### Your code here\n",
    "        self.X_train = X\n",
    "        self.Y_train = y\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def calculate_distances(self, X, one_x):\n",
    "        \"\"\"\n",
    "        This method calculates distances between one object and all other objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        one_x : numpy.array, shape = (n_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        dists = np.sqrt( np.sum( (X - one_x)**2, axis=1 ) )\n",
    "        return dists\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predicted labels\n",
    "        y_predicted = []\n",
    "        \n",
    "        ### Replace this line with your code:\n",
    "        max_dist = self.max_dist\n",
    "        use_kd_tree = self.use_kd_tree\n",
    "        use_weights = self.use_weights\n",
    "        \n",
    "        if use_kd_tree:\n",
    "            ckdtree = spatial.cKDTree(self.X_train, leafsize = 30)\n",
    "        \n",
    "\n",
    "        for one_x in X:\n",
    "            distances = self.calculate_distances(self.X_train, one_x)\n",
    "            if use_kd_tree:\n",
    "                r_neighbors_indeces = ckdtree.query_ball_point(one_x, max_dist)\n",
    "            else:    \n",
    "                r_neighbors_indeces = np.where(distances <= max_dist)\n",
    "                \n",
    "                #else:\n",
    "                #    sorted_indeces = distances.argsort()\n",
    "                #    r_neighbors_indeces = sorted_indeces[:1] # take the first k_neighbors elements           \n",
    "            if not use_weights:\n",
    "                r_neighbors_labels = self.Y_train[r_neighbors_indeces]\n",
    "                unique_labels, label_counts = np.unique(r_neighbors_labels, return_counts=True)\n",
    "                label_max_count = unique_labels[label_counts == label_counts.max()][0]\n",
    "            else:\n",
    "                label_weights = np.zeros(np.unique(self.Y_train).size)\n",
    "                \n",
    "                #label_weights[self.Y_train[r_neighbors_indeces]] += 1 / distances[r_neighbors_indeces]\n",
    "\n",
    "                for index in r_neighbors_indeces:\n",
    "                    weight = 1 / distances[index]\n",
    "                    label_weights[self.Y_train[index]] += weight\n",
    "                    \n",
    "                \n",
    "                label_max_count = np.argmax(label_weights)\n",
    "                \n",
    "            y_predicted.append(label_max_count)\n",
    "\n",
    "                \n",
    "        ### The end of your code\n",
    "        return np.array(y_predicted) # return numpy.array\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilities of each class for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            2D array with predicted probabilities of each class. \n",
    "            Example:\n",
    "                y_predicted_proba = [[0.1, 0.9],\n",
    "                                     [0.8, 0.2], \n",
    "                                     [0.0, 1.0], \n",
    "                                     ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predictions\n",
    "        y_predicted_proba = []\n",
    "        \n",
    "        ### Replace these lines with your code:\n",
    "        ckdtree = spatial.cKDTree(self.X_train, leafsize = 30)\n",
    "        for one_x in X:\n",
    "            distances = self.calculate_distances(self.X_train, one_x)\n",
    "            r_neighbors_indeces = ckdtree.query_ball_point(one_x, self.max_dist)\n",
    "            label_weights = np.zeros(np.unique(self.Y_train).size)\n",
    "            for index in r_neighbors_indeces:\n",
    "                weight = 1 / distances[index]\n",
    "                label_weights[self.Y_train[index]] += weight\n",
    "            y_predicted_proba.append(label_weights / sum(label_weights))\n",
    "        ### The end of your code\n",
    "            \n",
    "        return np.array(y_predicted_proba) # return numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (1 point) <br/>\n",
    "Create a matrix of object features `X` and vector of labels `y` for N=1000 objects using `sklearn.datasets.make_moons()` function from scikit-learn library. Also, set up random state in the function `random_state=42` and `noise=0.2`. To open the function description use `Shift` + `Tab` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "N = 1000\n",
    "X, y = make_moons(n_samples=N, noise=0.2, random_state=42)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[-0.112,  0.52 ],\n",
    "                [ 1.143, -0.343]])\n",
    "assert np.array_equal(np.round(X[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 point) <br/>\n",
    "\n",
    "Split the sample into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Use `random_state = 42` and `test_size = 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.5)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[ 0.77 , -0.289],\n",
    "                [ 0.239,  1.041]])\n",
    "assert np.array_equal(np.round(X_train[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) <br/>\n",
    "\n",
    "Modify class `KNNClassifier` above and implement `predict()` method that uses **max_dist** parameter to select neighbors like it's shown in the second figure (radius search). If there is no any object within **max_dist**, make decision based on the closest neighbor.\n",
    "\n",
    "<img src=\"img/knn2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.3 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "There are an algorithm [kd-tree](https://en.wikipedia.org/wiki/K-d_tree) that helps to find neighbors faster. Using [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.cKDTree.html#scipy.spatial.cKDTree) function modify you classifier to speed up **predict** method. Use `leafsize=30` in `KDTree`. Similar to `max_dist` option, add option `use_kd_tree = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.1 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 points) <br/>\n",
    "\n",
    "Now modify the **predict** method to provide prediction with neighbors weights.\n",
    "\n",
    "<img src=\"img/wv1.png\">\n",
    "\n",
    "<img src=\"img/wv2.png\">\n",
    "\n",
    "We propose you to use the following weights:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{1}{\\rho(x, x_{i})}\n",
    "$$\n",
    "\n",
    "Similar to `max_dist` option, add option `use_weights = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 66.5 ms\n",
      "Test accuracy of KNN classifier:  0.968\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.968, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Develop **predict_proba** method of the classifier. For each object this method returns probability that the object belongs to each of the classes. \n",
    "\n",
    "For each object $x$ probability for each class is defined as:\n",
    "\n",
    "$$\n",
    "p_{c}(x) = \\frac{g_{c}(x)}{\\sum_{i=1}^{C} g_{i}(x)}\n",
    "$$\n",
    "\n",
    "where $C$ is number of classes.\n",
    "\n",
    "Then, the object has a vector of probabilities:\n",
    "\n",
    "$$\n",
    "p(x) = (p_{1}(x), p_{2}(x), ..., p_{C}(x))\n",
    "$$\n",
    "\n",
    "Use neighbors weights as in Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict_proba = knn.predict_proba(X_test) # measure time for prediction\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[0.046, 0.954],\n",
    "                [0.962, 0.038]])\n",
    "assert np.array_equal(np.round(y_test_predict_proba[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
